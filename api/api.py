"""
FastAPI Book Recommendation Service

This module implements the data serving layer of the Book Recommendation
System. It exposes a REST API on top of the SQLite database generated by
the ETL pipeline and integrates a transformer-based recommendation engine.

FEATURES
--------
- Browse books with pagination
- Fetch a book by ISBN
- Trigger the ETL pipeline in the background
- Semantic book recommendation using transformers

HOW TO RUN
----------
Development / Production:
    uvicorn api.api:app --reload
"""

# ======================================================
# ENSURE PROJECT ROOT IS IN PYTHON PATH
# ======================================================

import sys
from pathlib import Path

PROJECT_ROOT = Path(__file__).resolve().parents[1]
sys.path.insert(0, str(PROJECT_ROOT))

# ======================================================
# STANDARD LIBRARIES
# ======================================================

import os
import subprocess
import threading
import re
from typing import List, Optional

# ======================================================
# THIRD-PARTY LIBRARIES
# ======================================================

from fastapi import FastAPI, Depends, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from sqlalchemy import create_engine, Column, String, Text
from sqlalchemy.orm import sessionmaker, declarative_base, Session
from pydantic import BaseModel, ConfigDict

# ======================================================
# PROJECT PATHS
# ======================================================

BASE_DIR = PROJECT_ROOT
DB_PATH = BASE_DIR / "data" / "storage_data" / "books.sqlite"
DB_PATH.parent.mkdir(parents=True, exist_ok=True)

# ======================================================
# DATABASE CONFIG
# ======================================================

SQLALCHEMY_DATABASE_URL = f"sqlite:///{DB_PATH}"

engine = create_engine(
    SQLALCHEMY_DATABASE_URL,
    connect_args={"check_same_thread": False}
)

SessionLocal = sessionmaker(
    autocommit=False,
    autoflush=False,
    bind=engine
)

Base = declarative_base()

# ======================================================
# DATABASE MODEL
# ======================================================

class Book(Base):
    __tablename__ = "books"

    record_id = Column(String, primary_key=True, index=True)
    book_key = Column(String, unique=True, index=True)
    status = Column(String)

    accession_no = Column(String, nullable=True)
    class_no_book_no = Column(String, nullable=True)
    pages = Column(String, nullable=True)

    title = Column(String, index=True)
    authors = Column(String, nullable=True)
    isbn = Column(String, index=True, nullable=True)
    year = Column(String, nullable=True)

    subjects = Column(String, nullable=True)
    summary = Column(Text, nullable=True)
    publisher = Column(String, nullable=True)

# ======================================================
# DEPENDENCY
# ======================================================

def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

# ======================================================
# HELPERS
# ======================================================

def normalize_isbn(isbn: str) -> str:
    return re.sub(r"[^0-9Xx]", "", isbn)

def safe_str(value):
    """Convert NaN / None to None for JSON safety"""
    if value is None:
        return None
    if isinstance(value, float) and value != value:
        return None
    return str(value)



# ======================================================
# RESPONSE SCHEMAS
# ======================================================

class BookResponse(BaseModel):
    record_id: str
    book_key: str
    status: str

    accession_no: Optional[str] = None
    class_no_book_no: Optional[str] = None
    pages: Optional[str] = None

    title: Optional[str] = None
    authors: Optional[str] = None
    isbn: Optional[str] = None
    year: Optional[str] = None

    subjects: Optional[str] = None
    summary: Optional[str] = None
    publisher: Optional[str] = None

    model_config = ConfigDict(from_attributes=True)

# ======================================================
# RECOMMENDATION SCHEMAS
# ======================================================

class RecommendationRequest(BaseModel):
    query: str
    top_k: int = 5


class RecommendationResult(BaseModel):
    record_id: Optional[str] = None
    book_key: Optional[str] = None
    status: Optional[str] = None

    accession_no: Optional[str] = None
    class_no_book_no: Optional[str] = None
    pages: Optional[str] = None

    title: Optional[str] = None
    authors: Optional[str] = None
    isbn: Optional[str] = None
    year: Optional[str] = None

    subjects: Optional[str] = None
    summary: Optional[str] = None
    publisher: Optional[str] = None

    score: float


# ======================================================
# FASTAPI APPLICATION
# ======================================================

app = FastAPI(
    title="Book Recommendation API",
    description="API for browsing and recommending books using transformers",
    version="1.1.0"
)

# ======================================================
# CORS
# ======================================================

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ======================================================
# TRANSFORMER RECOMMENDER (LAZY LOADED)
# ======================================================

recommender = None

@app.on_event("startup")
def load_recommender():
    """
    Load transformer models ONCE at application startup.
    """
    global recommender
    try:
        from recommender.advanced_transformer_recommender import (
            AdvancedTransformerRecommender
        )

        recommender = AdvancedTransformerRecommender(
            data_csv=BASE_DIR / "data" / "processed_data" / "books_features.csv",
            embedding_dir=BASE_DIR / "storage" / "embeddings"
        )

        print("✅ Transformer recommender loaded at startup")

    except Exception as e:
        recommender = None
        print("⚠️ Transformer recommender unavailable:", e)

# ======================================================
# ROUTES — DATA
# ======================================================

@app.get("/books/", response_model=List[BookResponse])
def get_books(skip: int = 0, limit: int = 50, db: Session = Depends(get_db)):
    return db.query(Book).offset(skip).limit(limit).all()


@app.get("/books/isbn/{isbn}", response_model=BookResponse)
def get_book_by_isbn(isbn: str, db: Session = Depends(get_db)):
    clean_isbn = normalize_isbn(isbn)
    book = db.query(Book).filter(Book.isbn == clean_isbn).first()

    if not book:
        raise HTTPException(status_code=404, detail="Book not found")

    return book

# ======================================================
# ROUTES — RECOMMENDATION
# ======================================================

@app.post("/recommend", response_model=List[RecommendationResult])
def recommend_books(req: RecommendationRequest):
    if recommender is None:
        raise HTTPException(
            status_code=503,
            detail="Recommendation service unavailable"
        )

    df = recommender.recommend(
        query=req.query,
        top_k=req.top_k
    )

    if df.empty:
        return []
    
    results = []
    for _, row in df.iterrows():
        results.append({
            "record_id": safe_str(row.get("record_id")),
            "book_key": safe_str(row.get("book_key")),
            "status": safe_str(row.get("status")),
            "accession_no": safe_str(row.get("accession_no")),
            "class_no_book_no": safe_str(row.get("class_no_book_no")),
            "pages": safe_str(row.get("pages")),
            "title": safe_str(row.get("title")),
            "authors": safe_str(row.get("authors")),
            "isbn": safe_str(row.get("isbn")),
            "year": safe_str(row.get("year")),
            "subjects": safe_str(row.get("subjects")),
            "summary": safe_str(row.get("summary")),
            "publisher": safe_str(row.get("publisher")),
            "score": float(row["final_score"])
        })

    return results
    
# ======================================================
# PIPELINE TRIGGER
# ======================================================

pipeline_lock = threading.Lock()

@app.post("/sync/")
def trigger_pipeline():
    """
    Trigger the ETL pipeline in the background.
    """
    def run_pipeline():
        if not pipeline_lock.acquire(blocking=False):
            return
        try:
            subprocess.run(
                [sys.executable, "main.py"],
                cwd=BASE_DIR
            )
        finally:
            pipeline_lock.release()

    threading.Thread(target=run_pipeline, daemon=True).start()

    return {
        "status": "started",
        "message": "Pipeline triggered in background"
    }
