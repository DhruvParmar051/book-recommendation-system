{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869a4b06",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'recommender'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m sys.path.append(\u001b[38;5;28mstr\u001b[39m(PROJECT_ROOT))\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrecommender\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhybrid_recommender\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HybridRecommender\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'recommender'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import sys\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2174ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to path: D:\\DAU\\SEM 2\\Big Data Engineering\\Project\\book-recommendation-system\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path().resolve().parent  # ‚Üê goes from notebooks ‚Üí project root\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(\"Added to path:\", PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26032d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  title class_no_book_no  \\\n",
      "28    computational intelligence : soft computing an...        006.3 kay   \n",
      "3157                                 multiagent systems        006.3 wei   \n",
      "3599       Current and Future Trends on AI Applications        006.3 ake   \n",
      "4634  layered learning in multiagent systems: a winn...        006.3 sto   \n",
      "4636  distributed reason maintenance for multiagent ...        006.3 kra   \n",
      "\n",
      "       intent     depth  \n",
      "28    applied  standard  \n",
      "3157  applied      deep  \n",
      "3599  applied  standard  \n",
      "4634  applied  standard  \n",
      "4636  applied  standard  \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Fix path\n",
    "PROJECT_ROOT = Path().resolve().parents[1]\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "from recommender.hybrid_recommender import HybridRecommender\n",
    "\n",
    "df = pd.read_json(\n",
    "    \"../data/enriched_data/enriched_books.json\",\n",
    "    orient=\"records\"\n",
    ")\n",
    "\n",
    "rec = HybridRecommender(df)\n",
    "\n",
    "result = rec.recommend(\n",
    "    record_id=\"981e5014a2cb501f989e0c8d8f5b423d\",\n",
    "    top_k=5\n",
    ")\n",
    "\n",
    "print(result[[\"title\", \"class_no_book_no\", \"intent\", \"depth\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b32030d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path().resolve()\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "\n",
    "RAW_DIR = DATA_DIR / \"raw_data\"\n",
    "INGESTED_DIR = DATA_DIR / \"ingested_data\"\n",
    "CLEAN_CSV = DATA_DIR / \"clean_data\" / \"clean_books.csv\"\n",
    "ENRICHED_JSON = DATA_DIR / \"enriched_data\" / \"enriched_books.json\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17fbfee",
   "metadata": {},
   "source": [
    "üì• 1. RAW DATA STATISTICS (Before Pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f452b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_files = list(RAW_DIR.glob(\"*.csv\"))\n",
    "raw_dfs = [pd.read_csv(f, encoding=\"latin1\", low_memory=False) for f in raw_files]\n",
    "\n",
    "raw_df = pd.concat(raw_dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3339563d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_raw_rows': 36364,\n",
       " 'unique_titles': 30906,\n",
       " 'missing_titles': np.int64(0),\n",
       " 'missing_isbn': np.int64(412)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_stats = {\n",
    "    \"total_raw_rows\": len(raw_df),\n",
    "    \"unique_titles\": raw_df[\"Title\"].nunique(dropna=True),\n",
    "    \"missing_titles\": raw_df[\"Title\"].isna().sum(),\n",
    "    \"missing_isbn\": raw_df[\"ISBN\"].isna().sum() if \"ISBN\" in raw_df else None,\n",
    "}\n",
    "raw_stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641843d6",
   "metadata": {},
   "source": [
    "üì• 2. INGESTED DATA STATISTICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2260c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingested_files = list(INGESTED_DIR.glob(\"*.csv\"))\n",
    "ingested_dfs = [pd.read_csv(f, encoding=\"latin1\", low_memory=False) for f in ingested_files]\n",
    "\n",
    "ingested_df = pd.concat(ingested_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e96a1163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_ingested_rows': 36364,\n",
       " 'unique_titles': 30906,\n",
       " 'unique_isbn': 31546,\n",
       " 'missing_isbn': np.int64(412),\n",
       " 'missing_year': np.int64(170)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingested_stats = {\n",
    "    \"total_ingested_rows\": len(ingested_df),\n",
    "    \"unique_titles\": ingested_df[\"title\"].nunique(),\n",
    "    \"unique_isbn\": ingested_df[\"isbn\"].nunique(dropna=True),\n",
    "    \"missing_isbn\": ingested_df[\"isbn\"].isna().sum(),\n",
    "    \"missing_year\": ingested_df[\"year\"].isna().sum(),\n",
    "}\n",
    "ingested_stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8add17",
   "metadata": {},
   "source": [
    "üßπ 3. CLEANED DATA STATISTICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67efb536",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = pd.read_csv(CLEAN_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7889d8fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_clean_rows': 31946,\n",
       " 'unique_record_id': 31946,\n",
       " 'unique_isbn': 26871,\n",
       " 'missing_isbn': np.int64(5075),\n",
       " 'duplicate_removed': 4418}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_stats = {\n",
    "    \"total_clean_rows\": len(clean_df),\n",
    "    \"unique_record_id\": clean_df[\"record_id\"].nunique(),\n",
    "    \"unique_isbn\": clean_df[\"isbn\"].nunique(dropna=True),\n",
    "    \"missing_isbn\": clean_df[\"isbn\"].isna().sum(),\n",
    "    \"duplicate_removed\": len(ingested_df) - len(clean_df),\n",
    "}\n",
    "clean_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d2acb7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'isbn_based_books': np.int64(26871), 'non_isbn_books': np.int64(5075)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "    \"isbn_based_books\": clean_df[\"isbn\"].notna().sum(),\n",
    "    \"non_isbn_books\": clean_df[\"isbn\"].isna().sum(),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8dafdf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ENRICHED_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "    enriched_data = json.load(f)\n",
    "\n",
    "enriched_df = pd.DataFrame(enriched_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38de5e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_processed': 31946,\n",
       " 'found_books': np.int64(9221),\n",
       " 'missing_books': np.int64(22725),\n",
       " 'success_rate_%': np.float64(28.86)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enrichment_stats = {\n",
    "    \"total_processed\": len(enriched_df),\n",
    "    \"found_books\": (enriched_df[\"status\"] == \"FOUND\").sum(),\n",
    "    \"missing_books\": (enriched_df[\"status\"] == \"MISSING\").sum(),\n",
    "    \"success_rate_%\": round(\n",
    "        100 * (enriched_df[\"status\"] == \"FOUND\").mean(), 2\n",
    "    ),\n",
    "}\n",
    "enrichment_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a3e4539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'authors_available': np.int64(8348),\n",
       " 'subjects_available': np.int64(8497),\n",
       " 'summary_available': np.int64(7313),\n",
       " 'publisher_available': np.int64(6708)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "    \"authors_available\": enriched_df[\"authors\"].notna().sum(),\n",
    "    \"subjects_available\": enriched_df[\"subjects\"].notna().sum(),\n",
    "    \"summary_available\": enriched_df[\"summary\"].notna().sum(),\n",
    "    \"publisher_available\": enriched_df[\"publisher\"].notna().sum(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c799961a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'final_books_count': 31895, 'unique_titles': 30246, 'unique_isbn': 26026}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_stats = {\n",
    "    \"final_books_count\": enriched_df[\"book_key\"].nunique(),\n",
    "    \"unique_titles\": enriched_df[\"title\"].nunique(),\n",
    "    \"unique_isbn\": enriched_df[\"isbn\"].nunique(dropna=True),\n",
    "}\n",
    "final_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35c36c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stage</th>\n",
       "      <th>rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Raw</td>\n",
       "      <td>36364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ingested</td>\n",
       "      <td>36364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cleaned</td>\n",
       "      <td>31946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Enriched</td>\n",
       "      <td>31946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      stage   rows\n",
       "0       Raw  36364\n",
       "1  Ingested  36364\n",
       "2   Cleaned  31946\n",
       "3  Enriched  31946"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = pd.DataFrame([\n",
    "    {\"stage\": \"Raw\", \"rows\": len(raw_df)},\n",
    "    {\"stage\": \"Ingested\", \"rows\": len(ingested_df)},\n",
    "    {\"stage\": \"Cleaned\", \"rows\": len(clean_df)},\n",
    "    {\"stage\": \"Enriched\", \"rows\": len(enriched_df)},\n",
    "])\n",
    "\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4d6e99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
